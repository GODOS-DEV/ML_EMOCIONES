# ğŸ­ Detector de Emociones Faciales en Tiempo Real

**Autor**: Joseph Efren Godos Zapata  
**Fecha**: 31/10/2025  

---

## ğŸ¯ DescripciÃ³n

Este proyecto implementa un sistema de reconocimiento de emociones humanas a partir de imÃ¡genes o video en vivo, utilizando una **Red Neuronal Convolucional (CNN)** entrenada con un dataset de rostros etiquetados y una **interfaz grÃ¡fica intuitiva** desarrollada en Python.

El sistema detecta rostros en tiempo real mediante la cÃ¡mara web o en imÃ¡genes cargadas manualmente, y clasifica la emociÃ³n predominante entre siete categorÃ­as:
- ğŸ˜  Enojado (`angry`)
- ğŸ¤¢ Disgusto (`disgust`)
- ğŸ˜¨ Miedo (`fear`)
- ğŸ˜Š Feliz (`happy`)
- ğŸ˜¢ Triste (`sad`)
- ğŸ˜² Sorpresa (`surprise`)
- ğŸ˜ Neutral (`neutral`)

---

## âš™ï¸ TecnologÃ­as Utilizadas

- **TensorFlow / Keras**: Entrenamiento y predicciÃ³n del modelo CNN.
- **OpenCV**: DetecciÃ³n de rostros y procesamiento de video.
- **Tkinter**: Interfaz grÃ¡fica de usuario (GUI).
- **PIL (Pillow)**: ManipulaciÃ³n de imÃ¡genes.
- **Matplotlib**: VisualizaciÃ³n de mÃ©tricas de entrenamiento.
- **Scikit-learn**: EvaluaciÃ³n del modelo (matriz de confusiÃ³n, reporte de clasificaciÃ³n).
- **NumPy, threading, os**: Soporte general.

Dataset utilizado: [Human Face Emotions (Kaggle)](https://www.kaggle.com/datasets/samithsachidanandan/human-face-emotions)

---

## ğŸ“ Estructura del Proyecto
Proyecto_ML/
â”œâ”€â”€ train_model.py # Script para entrenar el modelo CNN
â”œâ”€â”€ emociones.py # AplicaciÃ³n GUI para detecciÃ³n en tiempo real
â”œâ”€â”€ modelo_emociones.h5 # Modelo entrenado (generado tras ejecutar train_model.py)
â”œâ”€â”€ Data/ # Carpeta con subcarpetas por emociÃ³n (dataset)
â”‚ â”œâ”€â”€ angry/
â”‚ â”œâ”€â”€ disgust/
â”‚ â”œâ”€â”€ fear/
â”‚ â”œâ”€â”€ happy/
â”‚ â”œâ”€â”€ sad/
â”‚ â”œâ”€â”€ surprise/
â”‚ â””â”€â”€ neutral/
â””â”€â”€ README.md

---

## â–¶ï¸ Instrucciones de Uso

### Entrenar el modelo y ejecutar
```bash
python train_model.py
python emociones.py
Funcionalidades:
â–¶ï¸ INICIAR CÃMARA: Detecta emociones en tiempo real.
â¹ï¸ DETENER: Detiene la captura.
ğŸ–¼ï¸ CARGAR IMAGEN: Analiza una imagen estÃ¡tica.
ğŸ“ CARGAR MODELO: Permite seleccionar otro modelo .h5.
ğŸ“Š Resultados Esperados
PrecisiÃ³n tÃ­pica: 85%â€“90% en validaciÃ³n.
Interfaz visual con barras de progreso por emociÃ³n y porcentajes en tiempo real.
DetecciÃ³n robusta de rostros con Haar Cascade.
ğŸ”§ Posibles Mejoras Futuras
Integrar modelos preentrenados (ResNet, EfficientNet).
Soporte para mÃºltiples rostros simultÃ¡neos.
Exportar resultados a PDF o CSV.
VersiÃ³n web con Flask o Streamlit.
OptimizaciÃ³n para dispositivos mÃ³viles (TensorFlow Lite).
ğŸ“Œ Notas
El modelo asume que las emociones estÃ¡n en el orden:
['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral'].
Requiere conexiÃ³n a cÃ¡mara web para el modo en vivo.
Desarrollado y probado en Windows 10/11 con Python 3.9+.
ğŸ“ Licencia
Este proyecto es de uso educativo.
Â© 2025 Joseph Efren Godos Zapata

